---
title: "Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews"
collection: publications
permalink: /publication/30/4/2025-CHI25-PAF
excerpt: 'This project develops a more humanized LLM-powered conversational agent for hospital admission interviews that addresses the challenges of nurse shortages and time constraints. The system implements clinician-derived communication strategies through dynamic topic management with graph-based conversation flows and context-aware scaffolding using few-shot prompt tuning. Technical evaluation showed performance comparable to or exceeding human-written ground truth while outperforming prompt-engineered baselines, and a between-subject study (N=44) demonstrated significant improvements in user experience and data collection accuracy compared to existing solutions. The work contributes a framework for translating clinician expertise into algorithmic strategies for medical conversational agents, along with insights for balancing efficiency and empathy in healthcare interactions.'
date: 30/4/2025
venue: 'CHI&apos; 25'
paperurl: 'https://dl.acm.org/doi/10.1145/3706598.3714196'
citation: 'Dingdong Liu, Yujing Zhang, Bolin Zhao, Shuai Ma, Chuhan Shi, and Xiaojuan Ma. 2025. Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews. In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems (CHI &apos;25). Association for Computing Machinery, New York, NY, USA, Article 643, 1â€“23. https://doi.org/10.1145/3706598.3714196'
---
This project develops a more humanized LLM-powered conversational agent for hospital admission interviews that addresses the challenges of nurse shortages and time constraints. The system implements clinician-derived communication strategies through dynamic topic management with graph-based conversation flows and context-aware scaffolding using few-shot prompt tuning. Technical evaluation showed performance comparable to or exceeding human-written ground truth while outperforming prompt-engineered baselines, and a between-subject study (N=44) demonstrated significant improvements in user experience and data collection accuracy compared to existing solutions. The work contributes a framework for translating clinician expertise into algorithmic strategies for medical conversational agents, along with insights for balancing efficiency and empathy in healthcare interactions.

[Download paper here](https://dl.acm.org/doi/10.1145/3706598.3714196)

Recommended citation: Dingdong Liu, Yujing Zhang, Bolin Zhao, Shuai Ma, Chuhan Shi, Xiaojuan Ma